{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# from chromadb.config import Settings\n",
    "from youtube_transcript_api import YouTubeTranscriptApi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# assigning srt variable with the list \n",
    "# of dictionaries obtained by the get_transcript() function\n",
    "srt = YouTubeTranscriptApi.get_transcript(\"iLY_5DMndWY\")\n",
    "\n",
    "with open(\"subtitle.txt\", \"a\") as file:\n",
    "    for i in srt:\n",
    "        file.write(i['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the chroma settings\n",
    "# CHROMA_SETTINGS = Settings(\n",
    "#     chroma_db_impl = 'duckdb+parquet',\n",
    "#     persist_directory = 'db',\n",
    "#     anonymized_telemetry = False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader, PDFMinerLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings \n",
    "from langchain.vectorstores import Chroma\n",
    "import os\n",
    "# from constants import CHROMA_SETTINGS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = 'db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Python Hub\\\\GenAI\\\\Youtube Chatbot\\\\Chatbot-on-YouTube\\\\research'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Python Hub\\\\GenAI\\\\Youtube Chatbot\\\\Chatbot-on-YouTube'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    for root, dirs, files in os.walk('docs'):\n",
    "        for file in files:\n",
    "            if file.endswith(\".txt\"):\n",
    "                print(file)\n",
    "                loader = TextLoader(os.path.join(root,file))\n",
    "    documents = loader.load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=20)\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "    \n",
    "    # Create embeddings\n",
    "    embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "    # Create vector store\n",
    "    db = Chroma.from_documents(texts, embeddings, persist_directory=persist_directory)\n",
    "    \n",
    "    db.persist()\n",
    "    db=None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subtitle.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python Hub\\GenAI\\Youtube Chatbot\\Chatbot-on-YouTube\\myenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "d:\\Python Hub\\GenAI\\Youtube Chatbot\\Chatbot-on-YouTube\\myenv\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "d:\\Python Hub\\GenAI\\Youtube Chatbot\\Chatbot-on-YouTube\\myenv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python Hub\\GenAI\\Youtube Chatbot\\Chatbot-on-YouTube\\myenv\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create embeddings\n",
    "embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can load the persisted database from disk, and use it as normal.\n",
    "vectordb = Chroma(persist_directory=persist_directory,\n",
    "                  embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How NIRMA Changed Indian Detergent Market\".lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'how nirma changed indian detergent market'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python Hub\\GenAI\\Youtube Chatbot\\Chatbot-on-YouTube\\myenv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "docs = retriever.get_relevant_documents(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='he Nam named the detergent thathe formulated nirma and he would go onand make this a global brand he also puta beautiful illustration of a girl inthe white frog on the front of thepacket which was symbolic of her thiswas the beginning of the legendarywashing powder nirma now cenm decided totake his detergent to the market sowhile all the other prominent detergentBrands like Hindustan liver surf wasselling at 13.5 rupees per kg ksen bystarted selling his deterg nma at just3.5 rupees per kg this', metadata={'source': 'docs\\\\subtitle.txt'}),\n",
       " Document(page_content=\"but 1988 nirma hadcaptured 60% of the detergent market andhad overtaken the mainstream detergentserf just like the jingle claimed nirmahad become suban nirma and kasen'sMission to immortalize his daughter wasalso successful as of today nma is oneof the largest producers of sodash whenit comes to volumes along with this nIrma has also Diversified into manyother Industries like personal careproducts health care products IndustrialProducts education and the cementindustry his story is\", metadata={'source': 'docs\\\\subtitle.txt'}),\n",
       " Document(page_content=\"duringthe 1960s and '70s Multinational Brandswere selling detergents at very highprices which only the rich could affordmeaning most of the Indians were washingclothes laboriously using Ash soap nutsand whatnot looking at the situation in1969 kenv puts aside 7,000 Rupees toinvent a breakthrough detergent that themasses could afford and he startsexperimenting he starts making sodashand a few other ingredients after a lotof trial and error he finally gets theformula right and decides to\", metadata={'source': 'docs\\\\subtitle.txt'}),\n",
       " Document(page_content='rupees per kg this unique pricepoint of nma detergent immediatelygained the attention of everybody andmade it a local favorite among themiddle class and lower income groupsthis one man was manufacturing packagingand distributing the detergent all froma 10x 10 ft room in his house ksen bywould go around and bicycle every singleday and sell his homemade nma detergentdoor too after work it was after 3 yearsof selling nma on his bicycle when hefinally decided to open a shop inAhmedabad and quit his', metadata={'source': 'docs\\\\subtitle.txt'})]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "import base64\n",
    "import textwrap\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain. vectorstores import Chroma\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"MBZUAI/LaMini-T5-738M\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu and disk.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    checkpoint,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float32,\n",
    "    offload_folder=\"offload\"\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_pipeline():\n",
    "    pipe = pipeline(\n",
    "        'text2text-generation',\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        max_length=256,\n",
    "        do_sample=True,\n",
    "        temperature=0.3,\n",
    "        top_p=0.95\n",
    "\n",
    "    )\n",
    "\n",
    "    local_llm=HuggingFacePipeline(pipeline=pipe)\n",
    "    return local_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa_llm():\n",
    "    llm=llm_pipeline()\n",
    "    embeddings=SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "    db=Chroma(persist_directory=\"db\",embedding_function=embeddings)\n",
    "    retriever=db.as_retriever()\n",
    "    qa=RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=retriever,\n",
    "        return_source_documents=True\n",
    "    )\n",
    "\n",
    "    return qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_answer(instruction):\n",
    "    response=''\n",
    "    instruction=instruction\n",
    "    qa = qa_llm()\n",
    "    generated_text=qa(instruction)\n",
    "    answer=generated_text['result']\n",
    "    return answer, generated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python Hub\\GenAI\\Youtube Chatbot\\Chatbot-on-YouTube\\myenv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 0.3. An updated version of the class exists in the from rom langchain-huggingface package and should be used instead. To use it run `pip install -U from rom langchain-huggingface` and import as `from from rom langchain_huggingface import llms import HuggingFacePipeline`.\n",
      "  warn_deprecated(\n",
      "d:\\Python Hub\\GenAI\\Youtube Chatbot\\Chatbot-on-YouTube\\myenv\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "d:\\Python Hub\\GenAI\\Youtube Chatbot\\Chatbot-on-YouTube\\myenv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (573 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Nirma changed the Indian detergent market by introducing a unique price point of NMA detergent that was cheaper than other detergent brands.',\n",
       " {'query': 'how nirma changed indian detergent market',\n",
       "  'result': 'Nirma changed the Indian detergent market by introducing a unique price point of NMA detergent that was cheaper than other detergent brands.',\n",
       "  'source_documents': [Document(page_content='he Nam named the detergent thathe formulated nirma and he would go onand make this a global brand he also puta beautiful illustration of a girl inthe white frog on the front of thepacket which was symbolic of her thiswas the beginning of the legendarywashing powder nirma now cenm decided totake his detergent to the market sowhile all the other prominent detergentBrands like Hindustan liver surf wasselling at 13.5 rupees per kg ksen bystarted selling his deterg nma at just3.5 rupees per kg this', metadata={'source': 'docs\\\\subtitle.txt'}),\n",
       "   Document(page_content=\"but 1988 nirma hadcaptured 60% of the detergent market andhad overtaken the mainstream detergentserf just like the jingle claimed nirmahad become suban nirma and kasen'sMission to immortalize his daughter wasalso successful as of today nma is oneof the largest producers of sodash whenit comes to volumes along with this nIrma has also Diversified into manyother Industries like personal careproducts health care products IndustrialProducts education and the cementindustry his story is\", metadata={'source': 'docs\\\\subtitle.txt'}),\n",
       "   Document(page_content=\"duringthe 1960s and '70s Multinational Brandswere selling detergents at very highprices which only the rich could affordmeaning most of the Indians were washingclothes laboriously using Ash soap nutsand whatnot looking at the situation in1969 kenv puts aside 7,000 Rupees toinvent a breakthrough detergent that themasses could afford and he startsexperimenting he starts making sodashand a few other ingredients after a lotof trial and error he finally gets theformula right and decides to\", metadata={'source': 'docs\\\\subtitle.txt'}),\n",
       "   Document(page_content='rupees per kg this unique pricepoint of nma detergent immediatelygained the attention of everybody andmade it a local favorite among themiddle class and lower income groupsthis one man was manufacturing packagingand distributing the detergent all froma 10x 10 ft room in his house ksen bywould go around and bicycle every singleday and sell his homemade nma detergentdoor too after work it was after 3 yearsof selling nma on his bicycle when hefinally decided to open a shop inAhmedabad and quit his', metadata={'source': 'docs\\\\subtitle.txt'})]})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_answer(\"how nirma changed indian detergent market\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
